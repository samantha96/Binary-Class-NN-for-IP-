{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GCN for network attack.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMEvBZ1zuCMVBlDDpcNDSKY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samantha96/GCN-for-network-attack/blob/main/GCN_for_network_attack.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ns5iMrv66HtX"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import itertools\n",
        "import random\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "import torch as T\n",
        "device = T.device(\"cpu\")"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_VdrRotP8ks_"
      },
      "source": [
        "#import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GfZA5qKn8kvu"
      },
      "source": [
        "srcIP = pd.read_csv(\"/home/ml/bnn/data/unknownSrcIP17-5m.csv\", sep = '|',low_memory=False)\n",
        "#len(srcIP)\n",
        "srcIPBot = pd.read_csv(\"/home/ml/cnn/data/botSrcIP17.csv\", sep = '|',low_memory=False)\n",
        "\n",
        "print(len(srcIP))\n",
        "print(len(srcIPBot))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yaRpqgTE8kyJ"
      },
      "source": [
        "srcIP['label'] = 0\n",
        "srcIPBot['label'] = 1\n",
        "\n",
        "## Clean the fields\n",
        "#srcIP.srcIP= srcIP.srcIP.str.replace('.*&','')\n",
        "#srcIP.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQuQy65r8k0r"
      },
      "source": [
        "srcIP = [srcIP, srcIPBot]\n",
        "srcIP = pd.concat(srcIP)\n",
        "srcIP.reset_index(drop=True, inplace=True)\n",
        "\n",
        "print(len(srcIP))\n",
        "srcIP.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCOXDCXK8k2x"
      },
      "source": [
        "numBotSrcIP = len(srcIP.loc[srcIP[\"label\"] == 1]['srcIP'])\n",
        "print(f'Number of BotSrcIP: {numBotSrcIP}')\n",
        "numUnknownSrcIP = len(srcIP.loc[srcIP[\"label\"] == 0]['srcIP'])\n",
        "print(f'Number of UnknownSrcIP: {numUnknownSrcIP}')\n",
        "\n",
        "numUniBotSrcIP = len(srcIP.loc[srcIP[\"label\"] == 1]['srcIP'].unique())\n",
        "print(f'Number of Unique BotSrcIP: {numUniBotSrcIP}')\n",
        "numUniUnknownSrcIP = len(srcIP.loc[srcIP[\"label\"] == 0]['srcIP'].unique())\n",
        "print(f'Number of Unique UnknownSrcIP: {numUniUnknownSrcIP}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vb7vitOZ8k5j"
      },
      "source": [
        "### Use unique data\n",
        "#srcIP = srcIP.rename(columns = {'srciptypid': 'label'})\n",
        "srcIP = srcIP.groupby(['srcIP','label']).mean()\n",
        "srcIP = srcIP.reset_index('label')\n",
        "print(len(srcIP))\n",
        "srcIP.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sK_rS9v8k7-"
      },
      "source": [
        "srcIP = srcIP.drop(columns='keyid')\n",
        "srcIP.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BQmgC2d8k-d"
      },
      "source": [
        "labels = np.array(srcIP.pop('label'))\n",
        "labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTkU_xC88xoa"
      },
      "source": [
        "# Set random seed to ensure reproducible runs\n",
        "RSEED = 60\n",
        "\n",
        "# 30% examples in test data\n",
        "train, test, train_labels, test_labels = train_test_split(srcIP, labels, \n",
        "                                                          stratify = labels,\n",
        "                                                          test_size = 0.3, \n",
        "                                                          random_state = RSEED)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1HSlkQ8o8xrC"
      },
      "source": [
        "# Train and Test dataset informaiton\n",
        "print(f'Train dataset: {train.shape}')\n",
        "unique, counts = np.unique(train_labels, return_counts=True)\n",
        "print (np.asarray((unique, counts)).T)\n",
        "print(f'Test dataset: {test.shape}')\n",
        "unique, counts = np.unique(test_labels, return_counts=True)\n",
        "print (np.asarray((unique, counts)).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlI32QyI8xtz"
      },
      "source": [
        "train.head(2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J1mop5OC82V7"
      },
      "source": [
        "## Torch Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BeEBu-E08xwM"
      },
      "source": [
        "def acc_coarse(model, ds):\n",
        "  inpts = ds[:]['predictors']  # all rows\n",
        "  targets = ds[:]['target']    # all target 0s and 1s\n",
        "  with T.no_grad():\n",
        "    oupts = model(inpts)         # all computed ouputs\n",
        "  pred_y = oupts >= 0.5        # tensor of 0s and 1s\n",
        "  num_correct = T.sum(targets == pred_y)\n",
        "  acc = (num_correct.item() * 1.0 / len(ds))  # scalar\n",
        "  return acc, targets, oupts"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGq-GjP08xy2"
      },
      "source": [
        "class Classifier(T.nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Classifier, self).__init__()\n",
        "    self.hid1 = T.nn.Linear(27, 10) \n",
        "    self.hid2 = T.nn.Linear(10, 5)\n",
        "    self.oupt = T.nn.Linear(5, 1)\n",
        "\n",
        "    T.nn.init.xavier_uniform_(self.hid1.weight) \n",
        "    T.nn.init.zeros_(self.hid1.bias)\n",
        "    T.nn.init.xavier_uniform_(self.hid2.weight) \n",
        "    T.nn.init.zeros_(self.hid2.bias)\n",
        "    T.nn.init.xavier_uniform_(self.oupt.weight) \n",
        "    T.nn.init.zeros_(self.oupt.bias)\n",
        "\n",
        "  def forward(self, x):\n",
        "    z = T.tanh(self.hid1(x)) \n",
        "    z = T.tanh(self.hid2(z))\n",
        "    z = T.sigmoid(self.oupt(z)) \n",
        "    return z"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POhiSiEn8x1H"
      },
      "source": [
        "class ProcessDataset(T.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, data_file, label_file, num_rows=None):\n",
        "\n",
        "    self.x_data = T.tensor(data_file.values,\n",
        "      dtype=T.float32).to(device)\n",
        "    self.y_data = T.tensor(label_file,\n",
        "      dtype=T.float32).to(device)\n",
        "\n",
        "    self.y_data = self.y_data.reshape(-1,1)\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.x_data)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    if T.is_tensor(idx):\n",
        "      idx = idx.tolist()\n",
        "    preds = self.x_data[idx,:]  \n",
        "    lbl = self.y_data[idx,:]    \n",
        "    sample = { 'predictors' : preds, 'target' : lbl }\n",
        "\n",
        "    return sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ar4gZkKE8x3l"
      },
      "source": [
        "#### Plot Confusion Matrix\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import itertools\n",
        "from matplotlib.colors import Normalize\n",
        "import matplotlib.pyplot as plt\n",
        "#import matplotlib.cm as cm\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    plt.figure(figsize = (8, 8))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap, norm=Normalize(0,200))\n",
        "    #plt.imshow(cm, interpolation='bilinear', cmap=cmap, norm=Normalize(0,100))\n",
        "    plt.title(title, size = 24)\n",
        "    plt.colorbar(aspect=4)\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45, size = 14)\n",
        "    plt.yticks(tick_marks, classes, size = 14)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 4.\n",
        "    \n",
        "    # Labeling the plot\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt), fontsize = 20,\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"Green\" if cm[i, j] > thresh else \"Red\")\n",
        "        \n",
        "    plt.grid(None)\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label', size = 18)\n",
        "    plt.xlabel('Predicted label', size = 18)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhhYXqvN8x6C"
      },
      "source": [
        "%%time \n",
        "# Main\n",
        "# 0. get started\n",
        "print(\"\\nStart using PyTorch \\n\")\n",
        "T.manual_seed(1)\n",
        "np.random.seed(1)\n",
        "\n",
        "# 1. create Dataset and DataLoader objects\n",
        "print(\"Creating the train and test DataLoader \")\n",
        "\n",
        "train_ds = ProcessDataset(train, train_labels)  # all rows\n",
        "test_ds = ProcessDataset(test, test_labels)\n",
        "\n",
        "bat_size = 30000\n",
        "train_ldr = T.utils.data.DataLoader(train_ds,\n",
        "  batch_size=bat_size, shuffle=True)\n",
        "\n",
        "# 2. create neural network\n",
        "print(\"Creating 27-(10-10)-1 binary NN classifier \")\n",
        "model = Classifier().to(device)\n",
        "\n",
        "# 3. train network\n",
        "print(\"\\nPreparing training\")\n",
        "model = model.train()  # set training mode\n",
        "lrn_rate = 0.002\n",
        "loss_obj = T.nn.BCELoss()  # binary cross entropy\n",
        "optimizer = T.optim.SGD(model.parameters(),lr=lrn_rate)\n",
        "max_epochs = 200\n",
        "ep_log_interval = 10\n",
        "epoch_losses = []\n",
        "\n",
        "print(\"Loss function: \" + str(loss_obj))\n",
        "print(\"Optimizer: SGD\")\n",
        "print(\"Learn rate: \", lrn_rate)\n",
        "print(\"Batch size: \", bat_size)\n",
        "print(\"Max epochs: \" + str(max_epochs))\n",
        "\n",
        "print(\"\\nStarting training\")\n",
        "for epoch in range(0, max_epochs):\n",
        "    epoch_loss = 0.0            # for one full epoch\n",
        "    num_lines_read = 0\n",
        "\n",
        "    for (batch_idx, batch) in enumerate(train_ldr):\n",
        "      X = batch['predictors']  # [Batch size, 27] inputs\n",
        "      Y = batch['target']      # [Batch size,1]  targets\n",
        "      oupt = model(X)            # [Batch size,1]  computeds \n",
        "\n",
        "      loss_val = loss_obj(oupt, Y)   # a tensor\n",
        "      epoch_loss += loss_val.item()  # accumulate\n",
        "      # epoch_loss += loss_val  # is OK\n",
        "      # epoch_loss_custom += my_bce(model, batch)     \n",
        "    \n",
        "      optimizer.zero_grad() # reset all gradients\n",
        "      loss_val.backward()   # compute all gradients\n",
        "      optimizer.step()      # update all weights\n",
        "    \n",
        "    epoch_losses.append(epoch_loss)\n",
        "    if epoch % ep_log_interval == 0:\n",
        "      print(\"epoch = %4d   loss = %0.4f\" % (epoch, epoch_loss))\n",
        "      \n",
        "print(\"Training Done \")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NN3WEZ59EBM"
      },
      "source": [
        "#4. evaluate model\n",
        "model = model.eval()\n",
        "acc_train,train_target,train_prob = acc_coarse(model, train_ds)\n",
        "print(\"\\nAccuracy on train data = %0.2f%%\" % (acc_train * 100))\n",
        "acc_test,test_target,test_prob = acc_coarse(model, test_ds)\n",
        "print(\"Accuracy on test data = %0.2f%%\" % (acc_test * 100))\n",
        "\n",
        "# 5. save model\n",
        "print(\"\\nSaving trained model state_dict \\n\")\n",
        "path = \"./Models/saveCNNModel.pth\"\n",
        "T.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8yPeAep9EEF"
      },
      "source": [
        "print(len(test_target))\n",
        "len(test_prob)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsqV-SFF9EGe"
      },
      "source": [
        "results = pd.DataFrame(test_target.numpy().astype(int),columns=['trueLabel'])\n",
        "results['predProb'] = test_prob.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GJmrTopE9EI2"
      },
      "source": [
        "#Predict based on the threshold of the probability\n",
        "probCut = 0.5\n",
        "results['predLabel'] = results.predProb.apply(lambda x: 1 if x >= probCut else 0)\n",
        "print(results['trueLabel'].sum())\n",
        "print(results['predLabel'].sum())\n",
        "\n",
        "#cm = confusion_matrix(test_labels, predictions)\n",
        "cm = confusion_matrix(results['predLabel'], results['trueLabel'])\n",
        "#cm=cm.T\n",
        "cm[(0,0)], cm[(1,1)] = cm[(1,1)], cm[(0,0)]\n",
        "plot_confusion_matrix(cm, classes = ['BotSrcIP', 'UnknowSrcIP'],\n",
        "                      title = \"Test CM, Prob = \" + str(probCut) + \", Batch Size = \" + str(bat_size))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92eSbeff9M04"
      },
      "source": [
        "print(f'Train dataset: {train.shape}')\n",
        "unique, counts = np.unique(train_labels, return_counts=True)\n",
        "print (np.asarray((unique, counts)).T)\n",
        "print(f'Test dataset: {test.shape}')\n",
        "unique, counts = np.unique(test_labels, return_counts=True)\n",
        "print (np.asarray((unique, counts)).T)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFHB-Ftc9M3j"
      },
      "source": [
        "numMidProb20 = len(results.loc[(results[\"predProb\"] >= 0.4) & (results[\"predProb\"] <= 0.6)])\n",
        "print(\"# of IPs in the probability range (0.4 - 0.6):\", numMidProb20)\n",
        "numMidProb60 = len(results.loc[(results[\"predProb\"] >= 0.2) & (results[\"predProb\"] <= 0.8)])\n",
        "print(\"# of IPs in the probability range (0.2 - 0.8):\", numMidProb60)\n",
        "numMidProb80 = len(results.loc[(results[\"predProb\"] >= 0.1) & (results[\"predProb\"] <= 0.9)])\n",
        "print(\"# of IPs in the probability range (0.1 - 0.9):\", numMidProb80)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1D2pojiX9M6U"
      },
      "source": [
        "# Histogram Plot\n",
        "from matplotlib.patches import Rectangle\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10,10))\n",
        "colors = {0:'green', 1:'red'}\n",
        "#labels = ['Bot','Unknown']\n",
        "\n",
        "#plt.hist(results.predProb, color=\"green\")\n",
        "plt.hist([results.loc[results.trueLabel == x, 'predProb'] for x in colors], color=['green','red'])\n",
        "\n",
        "#create legend\n",
        "handles = [Rectangle((0,0),1,1,color=c,ec=\"k\") for c in ['green','red']]\n",
        "labels= [\"Unknown\",\"Bot\"]\n",
        "plt.legend(handles, labels)\n",
        "\n",
        "#plt.pie(results.predProb)\n",
        "plt.xlabel('Predict Probability')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title(\"Validate Predicted Probability Distribution\")\n",
        "plt.show();"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XqZ9SHOZ9M9e"
      },
      "source": [
        "import sklearn.metrics as metrics\n",
        "\n",
        "fpr, tpr, threshold = metrics.roc_curve(results['trueLabel'], results['predProb'])\n",
        "roc_auc = metrics.auc(fpr, tpr)\n",
        "\n",
        "plt.title('Receiver Operating Curve, bs=1000 in Distinct')\n",
        "plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
        "plt.legend(loc = 'lower right')\n",
        "plt.plot([0, 1], [0, 1],'r--')\n",
        "plt.xlim([0, 1])\n",
        "plt.ylim([0, 1])\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-LWFtxp9VVY"
      },
      "source": [
        "## Plot errors\n",
        "fig, ax = plt.subplots(1, 1)\n",
        "plt.title('Training Loss vs Epoch, lr=0.001, bs=1000, Distinct')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Training Loss', color = \"r\", fontsize=15)\n",
        "ax.plot(epoch_losses, 'r')\n",
        "#ax2 = ax.twinx()\n",
        "#ax2.plot(epochError[:100], 'g')\n",
        "#ax2.set_ylabel(\"Testing Error\",color=\"g\",fontsize=15)\n",
        "plt.draw()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}